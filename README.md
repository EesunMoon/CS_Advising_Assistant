# ğŸ“ CS Advising Assistant (LangChain + DeepSeek + RAG)

## ğŸš€ Project Overview
This project replaces **OpenAI API** with **Ollama-powered DeepSeek models**, integrating **LangChain** to build an AI-driven **CS Advising Assistant** using **RAG (Retrieval-Augmented Generation)**.

- **No OpenAI API Calls** â†’ Runs entirely on **Ollama-powered DeepSeek models**
- **LangChain Integration** â†’ Context retrieval and RAG-based response generation
- **FAISS for Efficient Search** â†’ Vector embedding-based document retrieval
- **Conversation Memory** â†’ Maintains context for better responses
- **Prompt Tuning** â†’ Enhances response quality


## ğŸ›  Tech Stack
### **LLM Execution**
- **Ollama** â†’ Runs **DeepSeek models** locally  
- **DeepSeek-Chat (via Ollama)** â†’ Generates responses without API costs  
- **LangChain ConversationalRetrievalChain** â†’ Enables context-aware responses  

### **Vector Embedding & Retrieval**
- **FAISS** â†’ Efficient similarity search for FAQ retrieval  
- **Hugging Face Sentence Embeddings** â†’ Replaces OpenAIâ€™s embedding API  

### **RAG Implementation**
- **Retrieves relevant FAQ entries**  
- **Augments context** before generating responses  
- **Optimized prompt tuning for response generation**  

### **Out-of-Scope Query Handling**
- **Vector embedding clustering** to detect irrelevant queries  

## ğŸ” How It Works
1. Retrieves the most relevant FAQ entries using FAISS & DeepSeek Embeddings
2. Retrieves additional context using LangChain Retriever
3. Optimizes prompts for better responses using Prompt Tuning
4. Generates responses using DeepSeek LLM via Ollama
5. Detects out-of-scope queries using vector embedding clustering
